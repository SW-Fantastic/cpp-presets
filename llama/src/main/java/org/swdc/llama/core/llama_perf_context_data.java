// Targeted by JavaCPP version 1.5.10: DO NOT EDIT THIS FILE

package org.swdc.llama.core;

import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import org.swdc.llama.core.ggml.*;
import static org.swdc.llama.core.ggml.GGML.*;

import static org.swdc.llama.core.LLamaCore.*;


    //
    // Performance utils
    //
    // NOTE: Used by llama.cpp examples/tools, avoid using in third-party apps. Instead, do your own performance measurements.
    //

    @Properties(inherit = org.swdc.llama.config.LLamaConfigure.class)
public class llama_perf_context_data extends Pointer {
        static { Loader.load(); }
        /** Default native constructor. */
        public llama_perf_context_data() { super((Pointer)null); allocate(); }
        /** Native array allocator. Access with {@link Pointer#position(long)}. */
        public llama_perf_context_data(long size) { super((Pointer)null); allocateArray(size); }
        /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
        public llama_perf_context_data(Pointer p) { super(p); }
        private native void allocate();
        private native void allocateArray(long size);
        @Override public llama_perf_context_data position(long position) {
            return (llama_perf_context_data)super.position(position);
        }
        @Override public llama_perf_context_data getPointer(long i) {
            return new llama_perf_context_data((Pointer)this).offsetAddress(i);
        }
    
        // ms == milliseconds
        public native double t_start_ms(); public native llama_perf_context_data t_start_ms(double setter);  // absolute start time
        public native double t_load_ms(); public native llama_perf_context_data t_load_ms(double setter);   // time needed for loading the model
        public native double t_p_eval_ms(); public native llama_perf_context_data t_p_eval_ms(double setter); // time needed for processing the prompt
        public native double t_eval_ms(); public native llama_perf_context_data t_eval_ms(double setter);   // time needed for generating tokens

        public native int n_p_eval(); public native llama_perf_context_data n_p_eval(int setter);   // number of prompt tokens
        public native int n_eval(); public native llama_perf_context_data n_eval(int setter);     // number of generated tokens
        public native int n_reused(); public native llama_perf_context_data n_reused(int setter);   // number of times a ggml compute graph had been reused
    }
